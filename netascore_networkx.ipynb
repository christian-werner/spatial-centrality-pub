{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and generate network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import algo.net_helper as nh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# PLEASE NOTE: \n",
    "# This script generates output files (graphs and assessed network files) in subdirectories\n",
    "# of the current workingdir (from where you execute this script) -> \"plots\" and \"net_out\"\n",
    "\n",
    "# network data input (as generated by NetAScore - see https://github.com/plus-mobilitylab/netascore)\n",
    "base_dir = \"/Users/christian/Documents/work/code/netascore/data\" # set to your input data directory\n",
    "compare_case_id = None\n",
    "case_id = \"denver_subset\"    # the case_id refers to the geopackage file name\n",
    "aoi_buffer_size = 5             # 5 for real-world net, 50 for generated grid (or half the cell size)\n",
    "is_generated_net = False        # set to True if using a generated grid network (with reference case)\n",
    "compare = False                 # set to True if using a generated grid network (with reference case)\n",
    "\n",
    "debug_routes = False\n",
    "\n",
    "edge_key = \"edge_id\" # CAUTION: currently, only \"edge_id\" is fully supported - using e.g. \"osm_id\" will cause errors when trying to join area back to edges\n",
    "if is_generated_net and compare:\n",
    "    case_id_prefix = str(case_id)\n",
    "    case_id = case_id_prefix + \"_subdiv\"\n",
    "    compare_case_id = case_id_prefix + \"_simple\"\n",
    "\n",
    "case_str = f\"{'gen_' if is_generated_net else ''}{case_id}\"\n",
    "net_file = f\"{base_dir}/netascore_{case_str}.gpkg\"\n",
    "compare_net_file = None\n",
    "\n",
    "cmap_diverging = \"PiYG\"\n",
    "cmap_centr = \"OrRd\"\n",
    " \n",
    "normalize = True\n",
    "\n",
    "edges = gpd.read_file(net_file, layer=\"edge\")\n",
    "# if input does not have 'edge_id' column, generate it from index\n",
    "if not 'edge_id' in edges.columns:\n",
    "    edges['edge_id'] = edges.index\n",
    "    print(\"created 'edge_id' column from gdf index.\")\n",
    "print(f\"Loaded {len(edges)} network edges\")\n",
    "nodes = gpd.read_file(net_file, layer=\"node\")\n",
    "if \"node_id\" in nodes.columns:\n",
    "    nodes.set_index('node_id', inplace=True)\n",
    "    print(\"set index to node_id\")\n",
    "else:\n",
    "    print(\"WARNING: 'node_id' is not present in nodes gdf - cannot set index.\")\n",
    "print(\"Nodes:\", len(nodes))\n",
    "# add edges ft+tf\n",
    "net_routing = nh.netascore_to_routable_net(edges)\n",
    "# generate NetworkX graph and find largest connected component\n",
    "g = nx.from_pandas_edgelist(net_routing, source='from_node', target='to_node', edge_attr=True, create_using=nx.MultiDiGraph, edge_key=edge_key)\n",
    "g = g.subgraph(max(nx.weakly_connected_components(g), key=len))\n",
    "# filter edge list accordingly\n",
    "filtered_edges = gpd.GeoDataFrame(nx.to_pandas_edgelist(g), crs=edges.crs)\n",
    "e_ids = filtered_edges.edge_id.unique()\n",
    "print(\"Edges in largest connected component:\", len(e_ids))\n",
    "edges = gpd.GeoDataFrame(edges.loc[edges.edge_id.isin(e_ids)])\n",
    "# filter nodes accordingly to match edge subset for visualisation\n",
    "filtered_nids = np.unique(np.append(edges.from_node.unique(), (edges.to_node.unique())))\n",
    "nodes = gpd.GeoDataFrame(nodes[nodes.index.isin(filtered_nids)])\n",
    "\n",
    "if compare_case_id is not None and compare_case_id != \"\":\n",
    "    compare_case_str = f\"{'gen_' if is_generated_net else ''}{compare_case_id}\"\n",
    "    compare_net_file = f\"{base_dir}/netascore_{compare_case_str}.gpkg\"\n",
    "    compare_edges = gpd.read_file(compare_net_file, layer=\"edge\")\n",
    "    compare_nodes = gpd.read_file(compare_net_file, layer=\"node\")\n",
    "    compare_net_routing = nh.netascore_to_routable_net(compare_edges)\n",
    "    compare_g = nx.from_pandas_edgelist(compare_net_routing, source='from_node', target='to_node', edge_attr=True, create_using=nx.MultiDiGraph, edge_key=edge_key)\n",
    "    compare_g = compare_g.subgraph(max(nx.weakly_connected_components(compare_g), key=len))\n",
    "    \n",
    "# generate polygon representing covered AOI extent\n",
    "aoi = nodes.unary_union.convex_hull.envelope\n",
    "# for generated network: extend to match common ebtw centrality reference case conditions\n",
    "if is_generated_net:\n",
    "    aoi = aoi.buffer(aoi_buffer_size, resolution=1).envelope\n",
    "else:\n",
    "    aoi = aoi.buffer(aoi_buffer_size)\n",
    "\n",
    "orig_crs = edges.crs\n",
    "print(f\"input CRS: {edges.crs}\")\n",
    "\n",
    "edges = edges.clip(aoi)\n",
    "\n",
    "net_routing.head()\n",
    "\n",
    "os.makedirs(os.path.join(\"plots\", \"svg\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(\"net_out\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shapely as sly\n",
    "if debug_routes:\n",
    "    # debugging of network connectivity etc.\n",
    "    o_id = nodes.sample().index.values[0]\n",
    "    d_id = nodes.sample().index.values[0]\n",
    "    paths = [p for p in nx.all_shortest_paths(g, o_id, d_id, weight='length')]\n",
    "    node_routes = []\n",
    "    for p in paths:\n",
    "        # direct line between nodes for simple vis\n",
    "        node_routes.append(sly.geometry.LineString([[a.x, a.y] for a in nodes.loc[p].geometry.values]))\n",
    "    map = nodes.set_crs(crs=32633, allow_override=True).explore()\n",
    "    rdf = gpd.GeoDataFrame(node_routes, columns=['geometry'])\n",
    "    rdf.set_crs(crs=32633, allow_override=True, inplace=True)\n",
    "    rdf['rid'] = range(1,len(paths)+1)\n",
    "    display(rdf.explore(m=map, column=\"rid\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute standard centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sp = nx.edge_betweenness_centrality(g, normalized=normalize, weight='length')\n",
    "nh.add_centr_to_netascore(edges, c_sp, \"sp\", edge_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    compare_c_sp = nx.edge_betweenness_centrality(compare_g, normalized=normalize, weight='length')\n",
    "    nh.add_centr_to_netascore(compare_edges, compare_c_sp, \"sp\", edge_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute o/d node weights\n",
    "### first: tesselate planar space based on network edges and compute each polygon's area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import momepy as mp\n",
    "if edges.crs.is_geographic:\n",
    "    edges.set_crs(crs=32633, allow_override=True, inplace=True)\n",
    "tess = mp.Tessellation(edges, unique_id = edge_key, limit=aoi)\n",
    "t = tess.tessellation\n",
    "print(f\"Tessellation created {len(tess.multipolygons)} multipolygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    if compare_edges.crs.is_geographic:\n",
    "        compare_edges.set_crs(crs=32633, allow_override=True, inplace=True)\n",
    "    compare_tess = mp.Tessellation(compare_edges, unique_id = \"edge_id\", limit=aoi)\n",
    "    compare_t = compare_tess.tessellation\n",
    "    print(f\"Tessellation created {len(compare_tess.multipolygons)} multipolygons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['area'] = t.geometry.area\n",
    "t.area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    compare_t['area'] = compare_t.geometry.area\n",
    "    compare_t.area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-index t to match edge_id (for joining with edges)\n",
    "t.set_index(edge_key, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nodes.crs.is_geographic:\n",
    "        nodes.set_crs(crs=32633, allow_override=True, inplace=True)\n",
    "nodes.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.explore(tooltip=['edge_id', 'from_node', 'to_node'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = net_routing.explore(tiles=\"CartoDB positron\", color=\"#A6D62A\")\n",
    "map = t.explore(m=map, color=\"#E2582C\", style_kwds={\"weight\":1, \"fillOpacity\":0.2})\n",
    "nodes.explore(m=map, color=\"#1F9F5E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Plotting tessellation\")\n",
    "ax = t.boundary.plot(edgecolor=\"red\", lw=0.2)\n",
    "ax = edges.plot(ax=ax, lw=0.5)\n",
    "ax = nodes.plot(ax=ax, markersize=0.5)\n",
    "plt.margins(0)\n",
    "plt.axis('off')\n",
    "plt.savefig(fname=f\"plots/{case_id}_tessel.pdf\", bbox_inches='tight')\n",
    "plt.savefig(fname=f\"plots/svg/{case_id}_tessel.svg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accumulate and assign edge-based weights per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_weights(edges, edge_weights):\n",
    "    # join network (edge list) f/t node columns with edge weight column\n",
    "    tmp = edges[['from_node','to_node', 'geometry']].join(edge_weights) # edge-based weight\n",
    "    display(tmp.explore(column=\"area\"))\n",
    "    wa = tmp.groupby(['from_node']).sum()[['area']]/2 # split edge weight to end nodes per edge\n",
    "    wa.index.rename(\"nid\", inplace=True)\n",
    "    wb = tmp.groupby(['to_node']).sum()['area']/2\n",
    "    wb.index.rename(\"nid\", inplace=True)\n",
    "    w = wa.join(wb, lsuffix='_a', rsuffix='_b', how='outer') # begin aggregation for each node role (from/to)\n",
    "    w.fillna(0, inplace=True) # set zero weight for nodes with non-existing weight input data\n",
    "    w['weight'] = w.area_a + w.area_b\n",
    "    dif = w.weight.sum() - edge_weights.sum()[0]\n",
    "    print(\"Sum of node weights\", \"equals\" if abs(dif) < 0.0001 else \"DOES NOT MATCH\", \"sum of edge weights\")\n",
    "    print(f\">>> total dif: {dif:.4f} --- sum of node weights: {w.weight.sum():.2f}, sum of edge weights: {edge_weights.sum()[0]:.2f}\")\n",
    "    print(f\">>> this equals to {dif/edge_weights.sum()[0]:.1%}\")\n",
    "    return w\n",
    "w = compute_node_weights(edges, t[['area']])\n",
    "if compare_net_file is not None:\n",
    "    compare_w = compute_node_weights(compare_edges, compare_t[['area']])\n",
    "w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[\"weight\"] = w.weight\n",
    "nodes.explore(column=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reference only: option to pre-compute the full interaction matrix (e.g. for use with the SIBC approach by Wu et al. 2022)\n",
    "def compute_interaction(node_weights):\n",
    "    nw_dict = node_weights[['weight']].to_dict()['weight']\n",
    "    interaction_dict = {}\n",
    "    sum_nw = node_weights[['weight']].sum().weight\n",
    "    node_weights['rel_weight'] = node_weights.weight / sum_nw\n",
    "    nw_rel_dict = node_weights[['rel_weight']].to_dict()['rel_weight']\n",
    "\n",
    "    for k1 in nw_dict:\n",
    "        for k2 in nw_rel_dict:\n",
    "            # w_orig * share_dest -> distribute w_orig across dest nodes\n",
    "            interaction_dict.setdefault((k1, k2), nw_dict[k1] * nw_rel_dict[k2])\n",
    "    \n",
    "    return interaction_dict "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute spatially normalised betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import algo.centrality as sbc\n",
    "c_sp_sbc = sbc.spatial_betweenness_centrality(g, w, w, normalized=normalize, weight='length')\n",
    "nh.add_centr_to_netascore(edges, c_sp_sbc, \"sp_sbc\", edge_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    compare_c_sp_sbc = sbc.spatial_betweenness_centrality(compare_g, compare_w, compare_w, normalized=normalize, weight='length')\n",
    "    nh.add_centr_to_netascore(compare_edges, compare_c_sp_sbc, \"sp_sbc\", edge_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare and explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.explore(column='centr_sp_sum', tiles=\"CartoDB darkmatter\", tooltip=['centr_sp_sum', 'centr_sp_sbc_sum', edge_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.explore(column='centr_sp_sbc_sum', tiles=\"CartoDB darkmatter\", tooltip=['osm_id', 'centr_sp_sbc_sum', 'centr_sp_sbc_ft', 'centr_sp_sbc_tf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    display(compare_edges.explore(column='centr_sp_sbc_sum', tiles=\"CartoDB darkmatter\", tooltip=['centr_sp_sbc_sum', 'centr_sp_sbc_ft', 'centr_sp_sbc_tf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    # compute difference between case and compare_case\n",
    "    d_a = edges[['edge_id', 'osm_id', 'from_node', 'to_node', 'geometry', 'centr_sp_sum', 'centr_sp_sbc_sum']].set_index('osm_id')\n",
    "    d_b = compare_edges[['edge_id', 'osm_id', 'from_node', 'to_node', 'centr_sp_sum', 'centr_sp_sbc_sum']].set_index('osm_id')\n",
    "    comp = d_a.join(d_b, lsuffix='_orig', rsuffix='_comp')\n",
    "    comp['cc_centr_sp_sum_dif'] = comp['centr_sp_sum_orig'] - comp['centr_sp_sum_comp']\n",
    "    comp['cc_centr_sp_sum_dif_rel'] = comp['cc_centr_sp_sum_dif'] / comp['centr_sp_sum_comp'] * 100\n",
    "    comp['cc_centr_sp_sbc_sum_dif'] = comp['centr_sp_sbc_sum_orig'] - comp['centr_sp_sbc_sum_comp']\n",
    "    comp['cc_centr_sp_sbc_sum_dif_rel'] = comp['cc_centr_sp_sbc_sum_dif'] / comp['centr_sp_sbc_sum_comp'] * 100\n",
    "    \n",
    "    # also add values for edges in subdivision\n",
    "    subdiv_ids = comp[[v.startswith('s') for v in comp.index.values]].index.values\n",
    "    for sid in subdiv_ids:\n",
    "        parts = sid.split(\".\")\n",
    "        if len(parts) < 4:\n",
    "            # no matching counterpart (inner subdiv)\n",
    "            # set centr_sp_sum_comp to 0\n",
    "            comp.loc[comp.index == sid, 'centr_sp_sum_comp'] = 0\n",
    "            comp.loc[comp.index == sid, 'centr_sp_sbc_sum_comp'] = 0\n",
    "            # set cc_centr_sp_sum_dif to orig - comp -> orig\n",
    "            comp.loc[comp.index == sid, 'cc_centr_sp_sum_dif'] = comp.loc[comp.index == sid, 'centr_sp_sum_orig']\n",
    "            comp.loc[comp.index == sid, 'cc_centr_sp_sbc_sum_dif'] = comp.loc[comp.index == sid, 'centr_sp_sbc_sum_orig']\n",
    "            # set (leave) cc_centr_sp_sum_dif_rel to NaN -> relative increase is +inf\n",
    "        else:\n",
    "            # set centr_sp_sum_comp to value of h/v.id\n",
    "            comp_val = d_b.loc[d_b.index == f\"{parts[2]}.{parts[3]}\", 'centr_sp_sum'].values\n",
    "            comp_val_s = d_b.loc[d_b.index == f\"{parts[2]}.{parts[3]}\", 'centr_sp_sbc_sum'].values\n",
    "            comp.loc[comp.index == sid, 'centr_sp_sum_comp'] = comp_val\n",
    "            comp.loc[comp.index == sid, 'centr_sp_sbc_sum_comp'] = comp_val_s\n",
    "            # set cc_centr_sp_sum_dif to orig - comp\n",
    "            dif_val = comp.loc[comp.index == sid, 'centr_sp_sum_orig'] - comp_val\n",
    "            comp.loc[comp.index == sid, 'cc_centr_sp_sum_dif'] = dif_val\n",
    "            dif_val_s = comp.loc[comp.index == sid, 'centr_sp_sbc_sum_orig'] - comp_val_s\n",
    "            comp.loc[comp.index == sid, 'cc_centr_sp_sbc_sum_dif'] = dif_val_s\n",
    "            # set cc_centr_sp_sum_dif_rel to dif / comp * 100\n",
    "            comp.loc[comp.index == sid, 'cc_centr_sp_sum_dif_rel'] = dif_val / comp_val * 100\n",
    "            comp.loc[comp.index == sid, 'cc_centr_sp_sbc_sum_dif_rel'] = dif_val_s / comp_val_s * 100\n",
    "    comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    display(comp.explore(column='cc_centr_sp_sum_dif_rel', tiles=\"CartoDB darkmatter\", tooltip=['centr_sp_sum_orig', 'centr_sp_sum_comp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges['dif_centr_sp-sbc'] = edges['centr_sp_sbc_sum'] - edges['centr_sp_sum']\n",
    "edges['rel_dif_centr_sp-sbc'] = (edges['centr_sp_sbc_sum'] - edges['centr_sp_sum']) / edges['centr_sp_sum'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_col = 'dif_centr_sp-sbc'\n",
    "maxval = np.abs(edges[comp_col].min())\n",
    "if np.abs(edges[comp_col].max()) > maxval:\n",
    "    maxval = np.abs(edges[comp_col].max())\n",
    "edges[edges[comp_col]!=0].explore(column=comp_col, tiles='CartoDB positron', cmap='RdBu', vmin = 0-maxval, vmax = maxval,\n",
    "        tooltip=[comp_col, 'centr_sp_sum', 'centr_sp_sbc_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_col = 'rel_dif_centr_sp-sbc'\n",
    "maxval = np.abs(edges[comp_col].min())\n",
    "if np.abs(edges[comp_col].max()) > maxval:\n",
    "    maxval = np.abs(edges[comp_col].max())\n",
    "edges[edges[comp_col]!=0].explore(column=comp_col, tiles='CartoDB positron', cmap='RdBu', vmin = 0-maxval, vmax = maxval,\n",
    "        tooltip=[comp_col, 'centr_sp_sum',  'centr_sp_sbc_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centr_plot(data, centr_col, label):\n",
    "    print(f\"Plotting column '{centr_col}'\")\n",
    "    #bins = compute_bins(data[delta_col], fac)\n",
    "    data.plot(column=centr_col, cmap=cmap_centr, legend=True, scheme=\"equalinterval\", \n",
    "            #x_ticks=None,\n",
    "            classification_kwds={'k':7}, \n",
    "            legend_kwds={\"fmt\": \"{:.3f}\", \"interval\":True,\n",
    "                            \"loc\":'upper left',\n",
    "                            'bbox_to_anchor':(1.01,1),\n",
    "                            'frameon':False,\n",
    "                            'title':f'${label}$\\n',\n",
    "                            'alignment':'center',\n",
    "                            'handletextpad':0.1,\n",
    "                            'labelspacing':0.65,\n",
    "                            'title_fontproperties':{'size':'large'}}\n",
    "            ) #'lowest': -d_max # known bug: https://github.com/pysal/mapclassify/issues/175\n",
    "    plt.margins(0)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(fname=f\"plots/{case_id}_{centr_col}.pdf\", bbox_inches='tight')\n",
    "    plt.savefig(fname=f\"plots/svg/{case_id}_{centr_col}.svg\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bins(data, fac=1):\n",
    "    d_max = abs(data.min()*fac)\n",
    "    if data.max()*fac > d_max:\n",
    "        d_max = data.max()*fac\n",
    "    d_max = math.ceil(d_max)\n",
    "    tmp = d_max\n",
    "    k = 7\n",
    "    d_max = math.ceil(d_max/k)*k\n",
    "    dif = d_max*2.0/k\n",
    "    cur = -d_max\n",
    "    print(f\"max val: {tmp}, dif: {dif}\")\n",
    "    bins = [] # upper bin bounds are used - the lowest needs to be skipped - otherwise \"-inf\" will be used as lower bound\n",
    "    while d_max - cur - dif > 0.001:\n",
    "        cur += dif\n",
    "        bins.append(cur)\n",
    "    bins.append(tmp)\n",
    "    bins = [x / fac for x in bins]\n",
    "    print(bins)\n",
    "    return bins\n",
    "\n",
    "def delta_plot(data, delta_col, label, unit = \" [%]\", fac=1):\n",
    "    print(f\"Plotting column '{delta_col}'\")\n",
    "    bins = compute_bins(data[delta_col], fac)\n",
    "    data.plot(column=delta_col, cmap=cmap_diverging, legend=True, scheme=\"UserDefined\", \n",
    "            classification_kwds={'bins':bins}, \n",
    "            legend_kwds={\"fmt\": \"{:.\" + str(len(str(fac))-1) + \"f}\", \"interval\":True,\n",
    "                            \"loc\":'upper left',\n",
    "                            'bbox_to_anchor':(1.01,1),\n",
    "                            'frameon':False,\n",
    "                            'title':f'$\\Delta {label}${unit}\\n',\n",
    "                            'alignment':'center',\n",
    "                            'handletextpad':0.1,\n",
    "                            'labelspacing':0.65,\n",
    "                            'title_fontproperties':{'size':'large'}}\n",
    "            ) #'lowest': -d_max # known bug: https://github.com/pysal/mapclassify/issues/175\n",
    "    plt.margins(0)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(fname=f\"plots/{case_id}_{delta_col}.pdf\", bbox_inches='tight')\n",
    "    plt.savefig(fname=f\"plots/svg/{case_id}_{delta_col}.svg\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    centr_plot(comp, 'centr_sp_sum_comp', 'c_Bref')\n",
    "    centr_plot(comp, 'centr_sp_sbc_sum_comp', 'c_{SB}ref')\n",
    "centr_plot(edges, 'centr_sp_sum', 'c_B')\n",
    "centr_plot(edges, 'centr_sp_sbc_sum', 'c_{SB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_plot(edges, 'rel_dif_centr_sp-sbc', 'c_B,c_{SB}')\n",
    "delta_plot(edges, 'dif_centr_sp-sbc', 'c_B,c_{SB}', unit=\"\", fac=100000)\n",
    "if compare_net_file is not None:\n",
    "    delta_plot(comp, 'cc_centr_sp_sum_dif_rel', 'c_B{ref},c_B')\n",
    "    delta_plot(comp, 'cc_centr_sp_sum_dif', 'c_B{ref},c_B', unit=\"\", fac=10000)\n",
    "    delta_plot(comp, 'cc_centr_sp_sbc_sum_dif_rel', 'c_{SB}{ref},c_{SB}')\n",
    "    delta_plot(comp, 'cc_centr_sp_sbc_sum_dif', 'c_{SB}{ref},c_{SB}', unit=\"\", fac=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_net_file is not None:\n",
    "    comp[comp.cc_centr_sp_sbc_sum_dif_rel > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.to_file(f\"net_out/{case_id}.gpkg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd7672cff37afb426fad2f749909436790e8aa38fd2e74a5158f7724f944c4a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
